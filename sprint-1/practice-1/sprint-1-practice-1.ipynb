{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "724c2367",
   "metadata": {},
   "source": [
    "# Time Series Analysis & Data Preparation \n",
    "\n",
    "Time series analysis is one of the most common types of data analysis, as it pertains to any data/information collected and stored over a period of time. This could be anything such as yearly sales, weekly temperatures, daily energy consumption, or even categorical such as recording the air quality per day! \n",
    "\n",
    "Time series analysis is also more complex than typical data anlysis, as you'll need to do a bit of work beforehand to determine the best course of action in our analysis - certain methods are dependant on the data having particular qualities! First let's start off with exploring some time series data, getting aquainted with the structure, and some basic transformations. \n",
    "\n",
    "## Bringing in some data\n",
    "\n",
    "We will set up our workspace and bring in some data on Stack Overflow question topics, found [here](https://www.kaggle.com/datasets/aishu200023/stackindex?resource=download). This data contains columns: \n",
    "\n",
    "- `month`: the month over which question topics were summed \n",
    "- `python`: the number of questions on stack overflow pertaining to python \n",
    "- `r`: the number of questions on stack overflow pertaining to r\n",
    "- `numpy`: the number of questions on stack overflow pertaining to numpy\n",
    "- `scipy`: the number of questions on stack overflow pertaining to scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65308545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4953d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "so = pd.read_csv('stack_overflow.csv')\n",
    "so.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7208e2f",
   "metadata": {},
   "source": [
    "## Basic exploration \n",
    "\n",
    "It is always a good idea to start off with some basic data exploration, similar to how you'd work with any other data type. This includes things like getting an overview of the data & values, and searching for any missing data, and even some cursory visualizations. \n",
    "\n",
    "Let's start by checking the data types of each column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ff609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "so.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d27037",
   "metadata": {},
   "source": [
    "We see that most columns are of numeric value type, whether it be float64 or int64. However, `month`, which indicates our date, is an object! Rather than a string, we want this to be in **datetime** format as that will communicate to pandas that this is time series data & will open up the use of some handy time transformations. \n",
    "\n",
    "We can use `pd.to_datetime()` to achieve this, inputting the column to be converted and the `format` of the string-type date. We need to communicate the format of our date string to pandas using **strftime abbreviations** so it can properly convert it. Our date is in a format such as `09-Jan`, where the first value abbreviated year (`%y`) and the second value is the abbreviated month name (`%b`). So for format we input `%y-%b`. \n",
    "\n",
    "[Here](https://www.geeksforgeeks.org/python-strftime-function/) is a helpful key for all the strftime abbreviations for translating these formats! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e1c4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "so['month'] =  pd.to_datetime(so['month'], format = '%y-%b')\n",
    "so.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c75faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "so.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898c9c34",
   "metadata": {},
   "source": [
    "See that the column type & value have been converted! \n",
    "\n",
    "Now we can use `describe` to get an idea of what values are in each column.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc88c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "so.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e646a98",
   "metadata": {},
   "source": [
    "We can easily check for missing values in a column or all columns using `isna()`. Recall that `NaN` values are 'not a number' and act as fill values when there is data missing (see [here](https://towardsdatascience.com/5-methods-to-check-for-nan-values-in-in-python-3f21ddd17eed) for a refresher if needed). \n",
    "\n",
    "Using `isna()` alone returns a boolean dataframe telling us which cells satisfy the condition of containing `NaN`. Chaining `sum()` to it provides a count of the number of `NaN` values in each column! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1672ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "so.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc3f2d5",
   "metadata": {},
   "source": [
    "Here we see that the `python` column is missing 7 values (contains 7 `NaN` values), `r` is missing 4, and `scipy` is missing 3. The `month` and `numpy` columns have no missing values. \n",
    "\n",
    "Visualization is especially important in time series analysis as our eye is often pretty good at picking out broad trends. Let's use **matplotlib** to create a basic time series plot with time on the x axis, and the count of questions on each topic/package on the y axis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fdbd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(so.month, so.python, c = 'b', label = 'Python')\n",
    "plt.plot(so.month, so.r, c = 'r', label = 'r')\n",
    "plt.plot(so.month, so.numpy, c = 'k', label = 'numpy')\n",
    "plt.plot(so.month, so.scipy, c = 'c', label = 'scipy')\n",
    "\n",
    "plt.title('Stack Overflow Questions')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.grid(which = 'major')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338c8c18",
   "metadata": {},
   "source": [
    "Great! We can see that by far python has the biggest growth in questions over time & the most questions asked overall. R experiences growth over time, but not nearly as much as python. Numpy and scipy have a small amount of questions and minimal growth over time. \n",
    "\n",
    "You can also see that there are some gaps in the data where we identified `NaN` values! This is shown as a break in the line & is most obvious for python around 2013, 2015 and 2017. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294e0869",
   "metadata": {},
   "source": [
    "## Filling missing values \n",
    "\n",
    "### Don't use mean filling! \n",
    "Before proceeding we want to fill any missing data with a meaningful value. In other words, we want to figure out what value we can replace any `NaN` values with. It is common to fill missing data with a mean or median values, but this is **not** recommended with time series data! We will demonstrate why mean-filling is not a good approach with time series data & demonstrate some useful alternatives.\n",
    "\n",
    "Let's create a new dataframe called `python` that only contains the `month` and `python` column from `so`. We will also add a new column called `meanfill` in which we use `fillna` to replace all `NaN` values with the mean of the original `python` column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ec91cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "py = so[['month', 'python']]\n",
    "py['meanfill'] = py['python'].fillna(py['python'].mean())\n",
    "py.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b0466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(py.month, py.python, c = 'b', linewidth = 3, label = 'original')\n",
    "plt.plot(py.month, py.meanfill, c = 'c', linestyle = '--', label = 'fill NaN with mean')\n",
    "\n",
    "plt.title('Stack Overflow Questions')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.grid(which = 'major')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9c3a2f",
   "metadata": {},
   "source": [
    "The above plot shows the original data in blue & the mean filled data in red. See how the filled values jump out! This is **not** a good method for filling values as time series data tends to grow/shrink over time in such a way that the mean value is not representative of the data at various points in time. \n",
    "\n",
    "### Interpolating values \n",
    "\n",
    "The suggested method for filling values in a time series is using interpolation, which can be done using the pandas **`interpolate`** function ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.interpolate.html)). Rather than hard-coding the value like we did with `fillna`, `interpolate` uses the values surrounding the missing value to guess a reasonable fill value. \n",
    "\n",
    "There are a variety of methods that can be used, the default being **`linear`** which according to the documentation ignores the data's index and treats the values as equally spaced. \n",
    "\n",
    "Let's add a column to our `python` dataframe containing linearly interpolated values & see how that compares to our mean-fill method. As a note, since we do not have any consecutive `NaN` values we do not need to specify the `fill direction` parameter. We also do not need to set the `limit` paramter which indicates the maximum number of consecutive `NaN`s to fill - this is so we do not fill long stretches of time with missing data, which tends to not be best practice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbad1a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "py['linear'] = py['python'].interpolate(method ='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7651fe",
   "metadata": {},
   "source": [
    "Another method we will demonstrate is **`pad`** which uses existing values to fill the gaps. `pad` works with a forward `limit_direction`, which means that a missing value will take on the value of that which came before it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b38027",
   "metadata": {},
   "outputs": [],
   "source": [
    "py['padded'] = py['python'].interpolate(method ='pad')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cf30f4",
   "metadata": {},
   "source": [
    "Let's add all these to a plot and do a quick eyeball analysis to see which performed best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50cfbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(py.month, py.meanfill, c = 'c', linestyle = '--', linewidth = 1, label = 'fill NaN with mean')\n",
    "plt.plot(py.month, py.linear, c = 'r', linestyle = '-.', linewidth = 4, label = 'linear interpolation')\n",
    "plt.plot(py.month, py.padded, c = 'b', linestyle = '--', linewidth = 4, label = 'padded')\n",
    "plt.plot(py.month, py.python, c = 'k', linewidth = 1, label = 'original')\n",
    "\n",
    "plt.title('Stack Overflow Questions')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.grid(which = 'major')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88495550",
   "metadata": {},
   "outputs": [],
   "source": [
    "py.iloc[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa144845",
   "metadata": {},
   "source": [
    "As mentioned previously the mean fill method is clearly not the best choice. You can see that there is little discernable visual difference between the linear interpolation & the padded fill values. Both of these seem to be good options and fit in reasonably well with the original data. \n",
    "\n",
    "Looking at the fill values themselves (see index 4), you can see that the padded interpolation value repeats the 768 value from index 3 to fill the missing value at 4. The linear interpolated value picks a value halfway between index 3 and 5 (values 768 and 1046) to fill the position at value 4 with 907. \n",
    "\n",
    "Exactly which method you use (linear interpolation, padding, or any other method available in the function) will have to be determined on a case by case basis depending on the data but these two are the most common & tend to be reliable in most cases. \n",
    "\n",
    "<hr style=\"border:2px solid gray\"> </hr>\n",
    "\n",
    "### Now you try! \n",
    "\n",
    "Fill the missing values from the `r` column in our `so` dataframe with using linear interpolation. Name the new column in `so` `r_interp`. Plot the original and filled versions together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d324e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION \n",
    "\n",
    "so['r_interp'] = so['r'].interpolate(method = 'linear')\n",
    "\n",
    "plt.plot(so.month, so.r, c = 'r', linestyle = '-', linewidth = 4, label = 'original')\n",
    "plt.plot(so.month, so.r_interp, c = 'k', linewidth = 1, label = 'padded')\n",
    "\n",
    "plt.title('Stack Overflow Questions on r')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.grid(which = 'major')\n",
    "\n",
    "### END SOLUTION "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a065ca5",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\"> </hr>\n",
    "\n",
    "## Resampling \n",
    "\n",
    "Another useful transformation for time series data is **resampling**. This means transforming the data frequency from finer to coarser - e.g. from daily data to weekly or monthly data. This can be achieved using pandas' `resample` function ([documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.resample.html)). \n",
    "\n",
    "We have yearly stack overflow question frequency on 'matlab' in the file `matlab_yearly.csv`. This contains the total number of questions asked about matlab **per year**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe094b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "matlab = pd.read_csv('matlab_yearly.csv')\n",
    "matlab['year'] = pd.to_datetime(matlab['year'], format = '%Y')\n",
    "matlab.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41298032",
   "metadata": {},
   "source": [
    "Say we want to compare this to our question frequency from the `r` column of our `so` dataframe to the yearly matlab values. We can try plotting them together, such as below, but the matlab data shows yearly sums, which is not readily comparable to the monthly sums shown for R! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532fff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(so.month, so.r_interp, c = 'b', label = 'r')\n",
    "plt.plot(matlab.year, matlab.matlab, c = 'r', label = 'matlab')\n",
    "\n",
    "plt.title('Stack Overflow Questions')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.grid(which = 'major')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abe7eed",
   "metadata": {},
   "source": [
    "Let's **resample** the `r_filled` column to show **yearly totals** rather than monthly values. \n",
    "\n",
    "We accomplish this usin `df.resample()` inputting a `freq` or frequency of `Y`, for year. Other `freq` inputs are possible such as `M` for monthly, `D` for daily, `3Y` for 3 yearly, but it must always be making the data **coarser**, not finer! \n",
    "\n",
    "We compute a summary value over the given time period by applying an operation like `sum` or `mean` to translate the monthly values into yearly values. In this case we will use `sum` to match the matlab data. \n",
    "\n",
    "For this to work, the index of the dataframe must be our datetime column, so we will apply that using `set_index`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c47cb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = so[['month', 'r_interp']]\n",
    "\n",
    "r.set_index('month', inplace = True)\n",
    "r_yearly = r.resample('Y').sum()\n",
    "r_yearly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aced51ea",
   "metadata": {},
   "source": [
    "You'll notice that in addition to the number of rows changing & the values now reflecting yarly totals, the index has changed as well. The index column called `month` now shows the last day of each year. Resampling will change your timestamp value in such a way that it reflects the **end** of the resampling period. \n",
    "\n",
    "You'll also notice that the headers are offset above the `month` column label. This is because resampling creates what is called a **multiindex**. We can do away with this for now by using `reset_index`. We will also rename the `month` column to `year`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b37077",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_yearly.reset_index(inplace = True)\n",
    "r_yearly.rename(columns = {'month': 'year'}, inplace = True)\n",
    "r_yearly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f053e48d",
   "metadata": {},
   "source": [
    "We are almost ready to make a comparison! One last thing stands in our way - the year index in `r_yearly` reflects that last day in the year, while the year in `matlab` reflects the first day of the year. We ideally want the two times to be the same. \n",
    "\n",
    "We can fix this in a number of ways, one being to just reset the `r_yearly` index with the `matlab` values\n",
    "\n",
    "        r_yearly.set_index(matlab.year, inplace = True)\n",
    "\n",
    "\n",
    "However, this only works if the time frame of the two datasets is identical. In this case it will work, but it's not the most reliable method! It would be better to implement a **time offset**. This is a method implemented after resampling to adjust back to the middle of the timeframe.  We can import `to_offset` from the `tseries.frequencies` pandas package which will allow us to do this. \n",
    "\n",
    "Let's make the `r_yearly` dates match those from `matlab` by subtracting 364 days. We will set our `loffset` to `364D` to indicate this. We will subtract this offset from our `year` column to create a new column, `year_offset`. This will transform our date from last day of the year to the first day of the year. It will be off by a day for leap years, but we will ignore that for now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e524aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.frequencies import to_offset\n",
    "\n",
    "loffset = '364D'\n",
    "r_yearly['year_offset'] = r_yearly['year'] - to_offset(loffset)\n",
    "r_yearly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9cc731",
   "metadata": {},
   "source": [
    "Now we can finally make a meaningful comparison! Let's plot the yearly `matlab` data alongside the new yearly `r_yearly` data. Remember we have to use the `year_offset` column we created as our x axis variable so it matches the matlab time frequency! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e500cffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(r_yearly.year_offset, r_yearly.r_interp, c = 'b', label = 'r')\n",
    "plt.plot(matlab.year, matlab.matlab, c = 'r', label = 'matlab')\n",
    "\n",
    "plt.title('Stack Overflow Questions')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.grid(which = 'major')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374534a2",
   "metadata": {},
   "source": [
    "Great, now we can meaningfully compare the two. It looks like matlab questions peaked in popularity in 2014-2015 and had steadily declined since then. In contrast, R seems to have greatly climbed in popularity until around 2017 when it began to level off. \n",
    "\n",
    "## Moving averages \n",
    "\n",
    "Another useful tool is the ability to create a **moving average** or a **rolling** average. This means computing an average for a defined window over and over again, passing through all the values. So say your window size was 3, you'd average values 1-3, then 2-4, then 3-5, etc. until you run out of values. This essentially batches your values in groups of 3 (or whatever window you choose). [This article](https://www.portent.com/blog/analytics/rolling-averages-math-moron.htm_) explains the concept in a bit more detail. This is effectively used to **smooth** and summarize a time series. \n",
    "\n",
    "We can do this using the `.rolling()` method in pandas. The input argument is a number which defines your window size, which is the width of the averaging window. \n",
    "\n",
    "Let's compute 6 monthly rolling averages of numpy questions on Stack Overflow. You will also chain the `mean` command at the end to get the average of each window. This could also be `sum` or any other operation! You'll notice that `6_month` in `numpy_rolling` has `NaN` for the first 5 values. This is because the method is trying to average each value & the three previous, but there are no three previous values. \n",
    "\n",
    "We will also add a column called `month_offset` that includes a 3 month offset from the original time, this way when we plot the time series, the value is placed in the center of the averaging window rather than the end! This is also good practice for plotting resampled data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b146ab3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prep \n",
    "numpy_rolling = so[['month', 'numpy']]\n",
    "numpy_rolling.set_index(\"month\", inplace = True)\n",
    "\n",
    "# compute rolling average \n",
    "numpy_rolling['six_month_roll'] = numpy_rolling['numpy'].rolling(6).mean()\n",
    "numpy_rolling.reset_index(inplace = True)\n",
    "\n",
    "# add time offset \n",
    "numpy_rolling['month_offset'] = numpy_rolling['month'] - to_offset('3M')\n",
    "\n",
    "# reorder cols \n",
    "numpy_rolling = numpy_rolling[['month', 'numpy', 'month_offset', 'six_month_roll']]\n",
    "numpy_rolling.iloc[0:13]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3c8924",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(numpy_rolling.month, numpy_rolling.numpy, c = 'k', linewidth = 1, label = 'monthly')\n",
    "plt.plot(numpy_rolling.month_offset, numpy_rolling.six_month_roll, linewidth = 2, \n",
    "         c = 'r', label = '6 month rolling average')\n",
    "\n",
    "plt.title('Numpy Stack Overflow Questions')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.grid(which = 'major')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364a3943",
   "metadata": {},
   "source": [
    "Now we have a plot showing the original monthly resolution as well as a 6 month rolling average! You can see the smoothing effect this operation has had on the data. This is helpful to remove noise and help reveal any underlying patterns that the noise may be concealing. We will cover more on \"noise\" in the coming practice.\n",
    "\n",
    "<hr style=\"border:2px solid gray\"> </hr>\n",
    "\n",
    "### Now you try\n",
    "\n",
    "Add a 1 year rolling average & time offset to `numpy_rolling`. Add the new line to the plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607a1238",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION \n",
    "\n",
    "# compute rolling average \n",
    "numpy_rolling['year_roll'] = numpy_rolling['numpy'].rolling(12).mean()\n",
    "numpy_rolling.reset_index(inplace = True)\n",
    "\n",
    "# add time offset \n",
    "numpy_rolling['year_offset'] = numpy_rolling['month'] - to_offset('6M')\n",
    "\n",
    "# plot \n",
    "plt.plot(numpy_rolling.month, numpy_rolling.numpy, c = 'k', linewidth = 1, label = 'monthly')\n",
    "plt.plot(numpy_rolling.month_offset, numpy_rolling.six_month_roll, linewidth = 3, \n",
    "         c = 'r', label = '6 month rolling average')\n",
    "plt.plot(numpy_rolling.year_offset, numpy_rolling.year_roll, linewidth = 3, \n",
    "         c = 'c', label = '1 year rolling average')\n",
    "\n",
    "plt.title('Numpy Stack Overflow Questions')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "plt.grid(which = 'major')\n",
    "\n",
    "### END SOLUTION "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f263ed1",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid gray\"> </hr>\n",
    "\n",
    "# Practice on your own \n",
    "\n",
    "In this practice section you will be working on Google search history data regarding the search frequency of several types of bears, obtained from [Google trends](https://trends.google.com/trends/explore?cat=66&date=all&geo=US&q=giant%20panda,grizzly%20bear,polar%20bear). These are contained in the file `google_bears.csv` where each column indicates the number of times the type of bear was searched per month in the US. \n",
    "\n",
    "#### Exercise 1. Read in `google_bears.csv` and determine how much data is missing from each column, if any. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bfc097",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION \n",
    "\n",
    "bears = pd.read_csv('google_bears.csv')\n",
    "bears.isna().sum()\n",
    "\n",
    "### END SOLUTION "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a2a9e7",
   "metadata": {},
   "source": [
    "#### Exercise 2. Convert the `Month` column from object to datetime. Be sure to indicating the appropriate string to date format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59afd958",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION \n",
    "\n",
    "bears['Month'] = pd.to_datetime(bears['Month'], format = '%Y-%m')\n",
    "bears.head()\n",
    "\n",
    "### END SOLUTION "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef273e0",
   "metadata": {},
   "source": [
    "#### Exercise 3. Use an appropriate method of your choice to fill the missing values in the `giant_panda` column. Plot the original vs the filled version. You can use something like `plt.figure(figsize = (12, 6))` to widen the figure window to better display the long time series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c4e7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION \n",
    "\n",
    "bears['giant_panda_interp'] = bears['giant_panda'].interpolate(method ='linear')\n",
    "\n",
    "plt.figure(figsize = (12, 6))\n",
    "plt.plot(bears.Month, bears.giant_panda, linewidth = 3, c = 'k', label = 'original')\n",
    "plt.plot(bears.Month, bears.giant_panda_interp, linewidth = 1, c = 'r', label = 'interpolated')\n",
    "plt.legend()\n",
    "plt.grid(which = 'major')\n",
    "plt.title('Giant Pandas Google Searches')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Search Count')\n",
    "\n",
    "### END SOLUTION "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb74762",
   "metadata": {},
   "source": [
    "#### Exercise 4. Resample the searches for grizzly to be on a yearly timeframe. Use the summary metric of your chocie. Plot the original & resampled data using the appropriate time offset. That means rather than plotting the data point at the end of the year, make sure it is placed in the middle of the year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200093dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION \n",
    "\n",
    "bears_yearly = bears.set_index('Month').resample('Y').mean()\n",
    "bears_yearly.reset_index(inplace = True)\n",
    "bears_yearly['Month_offset'] = bears_yearly['Month'] - to_offset('6M')\n",
    "\n",
    "plt.figure(figsize = (12, 6))\n",
    "plt.plot(bears.Month, bears.grizzly_bear, linewidth = 3, c = 'k', label = 'monthly')\n",
    "plt.plot(bears_yearly.Month_offset, bears_yearly.grizzly_bear, \n",
    "         linewidth = 3, c = 'r', label = 'yearly average')\n",
    "plt.legend()\n",
    "plt.grid(which = 'major')\n",
    "plt.title('Grizzly Bear Google Searches')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Search Count')\n",
    "\n",
    "### END SOLUTION "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc73b20",
   "metadata": {},
   "source": [
    "#### Exercise 5.  Create a plot with the original monthly polar bear data, a 90 day moving average, and yearly resampled data. Make sure to include a legend. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d069650",
   "metadata": {},
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION \n",
    "\n",
    "# get rolling\n",
    "bears_rolling = bears[['Month', 'polar_bear']]\n",
    "bears_rolling.set_index(\"Month\", inplace = True)\n",
    "\n",
    "bears_rolling = bears_rolling.rolling(3).mean()\n",
    "bears_rolling.reset_index(inplace = True)\n",
    "bears_rolling['Month_offset'] = bears_rolling['Month'] - to_offset('45D')\n",
    "\n",
    "# plot \n",
    "plt.figure(figsize = (12, 6))\n",
    "plt.plot(bears.Month, bears.polar_bear, linewidth = 3, c = 'k', label = 'monthly')\n",
    "plt.plot(bears_yearly.Month_offset, bears_yearly.polar_bear, \n",
    "         linewidth = 3, c = 'r', label = 'yearly average')\n",
    "plt.plot(bears_rolling.Month_offset, bears_rolling.polar_bear, \n",
    "         linewidth = 2, c = 'c', label = '3 month rolling average')\n",
    "plt.legend()\n",
    "plt.grid(which = 'major')\n",
    "plt.title('Polar Bear Google Searches')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Search Count')\n",
    "\n",
    "\n",
    "### END SOLUTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815a3046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fbcd91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
